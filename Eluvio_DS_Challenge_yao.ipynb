{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import math\n",
    "import statistics\n",
    "import matplotlib.pylab as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/michaelyao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/michaelyao/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/michaelyao/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/michaelyao/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /Users/michaelyao/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/michaelyao/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/michaelyao/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/michaelyao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#pip install nltk==3.3\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "#pip install pycountry\n",
    "#pip install geograpy3\n",
    "#pip install pycountry-convert\n",
    "import pycountry\n",
    "from geograpy import extraction\n",
    "nltk.download('twitter_samples')\n",
    "from nltk.corpus import twitter_samples\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re, string\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "import country_converter as coco\n",
    "from nltk import classify\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding new columns to the datasets. The columns include the year of the video; the mean, median and particular percentiles of up_votes number in the year each video belong to; two indicators to indicate whether the video has more upvotes than the median/ 75 percentile upvotes of that year, which are used to classify the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eluvio = pd.read_csv(\"Eluvio_DS_Challenge.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_list = list(eluvio['author'])\n",
    "dates = list(eluvio['date_created'])\n",
    "titles = list(eluvio['title'])\n",
    "votes = list(eluvio['up_votes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = {}\n",
    "for date in dates:\n",
    "    year = date[:4]\n",
    "    if year not in years:\n",
    "        years[year] = 1\n",
    "    else:\n",
    "        years[year] = years[year]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2008': [0, 22505],\n",
       " '2009': [22505, 47620],\n",
       " '2010': [47620, 70933],\n",
       " '2011': [70933, 109819],\n",
       " '2012': [109819, 152462],\n",
       " '2013': [152462, 240693],\n",
       " '2014': [240693, 332723],\n",
       " '2015': [332723, 427344],\n",
       " '2016': [427344, 509236]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_index = {}\n",
    "index = 0\n",
    "for year in years:\n",
    "    index = index+years[year]\n",
    "    year_index[year] = index\n",
    "year_index_dict = {\n",
    " '2008': [0,22505],\n",
    " '2009': [22505,47620],\n",
    " '2010': [47620,70933],\n",
    " '2011': [70933,109819],\n",
    " '2012': [109819,152462],\n",
    " '2013': [152462,240693],\n",
    " '2014': [240693,332723],\n",
    " '2015': [332723,427344],\n",
    " '2016': [427344,509236]\n",
    "}\n",
    "year_index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_col = []\n",
    "for year in years:\n",
    "    temp = [year]*years[year]\n",
    "    year_col = year_col+temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "eluvio['year'] = year_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_dict = {}\n",
    "mean_dict = {}\n",
    "percentile75_dict = {}\n",
    "percentile80_dict = {}\n",
    "percentile85_dict = {}\n",
    "percentile90_dict = {}\n",
    "percentile95_dict = {}\n",
    "for year_number in range(2008,2017):\n",
    "    year = str(year_number)\n",
    "    votes_this_year = votes[year_index_dict[year][0]:year_index_dict[year][1]]\n",
    "    median_dict[year] = statistics.median(votes_this_year)\n",
    "    mean_dict[year] = statistics.mean(votes_this_year)\n",
    "    percentile75_dict[year] = np.percentile(votes_this_year,75)\n",
    "    percentile80_dict[year] = np.percentile(votes_this_year,80)\n",
    "    percentile85_dict[year] = np.percentile(votes_this_year,85)\n",
    "    percentile90_dict[year] = np.percentile(votes_this_year,90)\n",
    "    percentile95_dict[year] = np.percentile(votes_this_year,95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_col = []\n",
    "mean_col = []\n",
    "percentile75_col = []\n",
    "percentile80_col = []\n",
    "percentile85_col = []\n",
    "percentile90_col = []\n",
    "percentile95_col = []\n",
    "for year in years:\n",
    "    temp_median = [median_dict[year]]*years[year]\n",
    "    temp_mean = [mean_dict[year]]*years[year]\n",
    "    temp_75 = [percentile75_dict[year]]*years[year]\n",
    "    temp_80 = [percentile80_dict[year]]*years[year]\n",
    "    temp_85 = [percentile85_dict[year]]*years[year]\n",
    "    temp_90 = [percentile90_dict[year]]*years[year]\n",
    "    temp_95 = [percentile95_dict[year]]*years[year]\n",
    "    median_col = median_col+temp_median\n",
    "    mean_col = mean_col+temp_mean\n",
    "    percentile75_col = percentile75_col+temp_75\n",
    "    percentile80_col = percentile80_col+temp_80\n",
    "    percentile85_col = percentile85_col+temp_85\n",
    "    percentile90_col = percentile90_col+temp_90\n",
    "    percentile95_col = percentile95_col+temp_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "eluvio['median_this_year'] = median_col\n",
    "eluvio['mean_this_year'] = mean_col\n",
    "eluvio['percentile75_year'] = percentile75_col\n",
    "eluvio['percentile80_year'] = percentile80_col\n",
    "eluvio['percentile85_year'] = percentile85_col\n",
    "eluvio['percentile90_year'] = percentile90_col\n",
    "eluvio['percentile95_year'] = percentile95_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "indi = []\n",
    "for i in range(len(votes)):\n",
    "    if votes[i] > median_col[i]:\n",
    "        indi.append(1)\n",
    "    else:\n",
    "        indi.append(0)\n",
    "eluvio['greater_than_median'] = indi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "indi = []\n",
    "for i in range(len(votes)):\n",
    "    if votes[i] > percentile75_col[i]:\n",
    "        indi.append(1)\n",
    "    else:\n",
    "        indi.append(0)\n",
    "eluvio['greater_than_75'] = indi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_created</th>\n",
       "      <th>date_created</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>title</th>\n",
       "      <th>over_18</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "      <th>year</th>\n",
       "      <th>median_this_year</th>\n",
       "      <th>mean_this_year</th>\n",
       "      <th>percentile75_year</th>\n",
       "      <th>percentile80_year</th>\n",
       "      <th>percentile85_year</th>\n",
       "      <th>percentile90_year</th>\n",
       "      <th>percentile95_year</th>\n",
       "      <th>greater_than_median</th>\n",
       "      <th>greater_than_75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1201232046</td>\n",
       "      <td>2008-01-25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Scores killed in Pakistan clashes</td>\n",
       "      <td>False</td>\n",
       "      <td>polar</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.823906</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>63.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1201232075</td>\n",
       "      <td>2008-01-25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Japan resumes refuelling mission</td>\n",
       "      <td>False</td>\n",
       "      <td>polar</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.823906</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>63.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1201232523</td>\n",
       "      <td>2008-01-25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>US presses Egypt on Gaza border</td>\n",
       "      <td>False</td>\n",
       "      <td>polar</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.823906</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>63.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1201233290</td>\n",
       "      <td>2008-01-25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Jump-start economy: Give health care to all</td>\n",
       "      <td>False</td>\n",
       "      <td>fadi420</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.823906</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>63.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1201274720</td>\n",
       "      <td>2008-01-25</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Council of Europe bashes EU&amp;UN terror blacklist</td>\n",
       "      <td>False</td>\n",
       "      <td>mhermans</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.823906</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>63.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509231</th>\n",
       "      <td>1479816764</td>\n",
       "      <td>2016-11-22</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Heil Trump : Donald Trump s  alt-right  white...</td>\n",
       "      <td>False</td>\n",
       "      <td>nonamenoglory</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2016</td>\n",
       "      <td>5.0</td>\n",
       "      <td>182.005654</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>170.9</td>\n",
       "      <td>747.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509232</th>\n",
       "      <td>1479816772</td>\n",
       "      <td>2016-11-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>There are people speculating that this could b...</td>\n",
       "      <td>False</td>\n",
       "      <td>SummerRay</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2016</td>\n",
       "      <td>5.0</td>\n",
       "      <td>182.005654</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>170.9</td>\n",
       "      <td>747.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509233</th>\n",
       "      <td>1479817056</td>\n",
       "      <td>2016-11-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Professor receives Arab Researchers Award</td>\n",
       "      <td>False</td>\n",
       "      <td>AUSharjah</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2016</td>\n",
       "      <td>5.0</td>\n",
       "      <td>182.005654</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>170.9</td>\n",
       "      <td>747.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509234</th>\n",
       "      <td>1479817157</td>\n",
       "      <td>2016-11-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Nigel Farage attacks response to Trump ambassa...</td>\n",
       "      <td>False</td>\n",
       "      <td>smilyflower</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2016</td>\n",
       "      <td>5.0</td>\n",
       "      <td>182.005654</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>170.9</td>\n",
       "      <td>747.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509235</th>\n",
       "      <td>1479817346</td>\n",
       "      <td>2016-11-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Palestinian wielding knife shot dead in West B...</td>\n",
       "      <td>False</td>\n",
       "      <td>superislam</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>2016</td>\n",
       "      <td>5.0</td>\n",
       "      <td>182.005654</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>170.9</td>\n",
       "      <td>747.45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509236 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time_created date_created  up_votes  down_votes  \\\n",
       "0         1201232046   2008-01-25         3           0   \n",
       "1         1201232075   2008-01-25         2           0   \n",
       "2         1201232523   2008-01-25         3           0   \n",
       "3         1201233290   2008-01-25         1           0   \n",
       "4         1201274720   2008-01-25         4           0   \n",
       "...              ...          ...       ...         ...   \n",
       "509231    1479816764   2016-11-22         5           0   \n",
       "509232    1479816772   2016-11-22         1           0   \n",
       "509233    1479817056   2016-11-22         1           0   \n",
       "509234    1479817157   2016-11-22         1           0   \n",
       "509235    1479817346   2016-11-22         1           0   \n",
       "\n",
       "                                                    title  over_18  \\\n",
       "0                       Scores killed in Pakistan clashes    False   \n",
       "1                        Japan resumes refuelling mission    False   \n",
       "2                         US presses Egypt on Gaza border    False   \n",
       "3            Jump-start economy: Give health care to all     False   \n",
       "4         Council of Europe bashes EU&UN terror blacklist    False   \n",
       "...                                                   ...      ...   \n",
       "509231   Heil Trump : Donald Trump s  alt-right  white...    False   \n",
       "509232  There are people speculating that this could b...    False   \n",
       "509233          Professor receives Arab Researchers Award    False   \n",
       "509234  Nigel Farage attacks response to Trump ambassa...    False   \n",
       "509235  Palestinian wielding knife shot dead in West B...    False   \n",
       "\n",
       "               author   category  year  median_this_year  mean_this_year  \\\n",
       "0               polar  worldnews  2008               1.0       15.823906   \n",
       "1               polar  worldnews  2008               1.0       15.823906   \n",
       "2               polar  worldnews  2008               1.0       15.823906   \n",
       "3             fadi420  worldnews  2008               1.0       15.823906   \n",
       "4            mhermans  worldnews  2008               1.0       15.823906   \n",
       "...               ...        ...   ...               ...             ...   \n",
       "509231  nonamenoglory  worldnews  2016               5.0      182.005654   \n",
       "509232      SummerRay  worldnews  2016               5.0      182.005654   \n",
       "509233      AUSharjah  worldnews  2016               5.0      182.005654   \n",
       "509234    smilyflower  worldnews  2016               5.0      182.005654   \n",
       "509235     superislam  worldnews  2016               5.0      182.005654   \n",
       "\n",
       "        percentile75_year  percentile80_year  percentile85_year  \\\n",
       "0                     5.0                7.0               10.0   \n",
       "1                     5.0                7.0               10.0   \n",
       "2                     5.0                7.0               10.0   \n",
       "3                     5.0                7.0               10.0   \n",
       "4                     5.0                7.0               10.0   \n",
       "...                   ...                ...                ...   \n",
       "509231               19.0               29.0               55.0   \n",
       "509232               19.0               29.0               55.0   \n",
       "509233               19.0               29.0               55.0   \n",
       "509234               19.0               29.0               55.0   \n",
       "509235               19.0               29.0               55.0   \n",
       "\n",
       "        percentile90_year  percentile95_year  greater_than_median  \\\n",
       "0                    18.0              63.00                    1   \n",
       "1                    18.0              63.00                    1   \n",
       "2                    18.0              63.00                    1   \n",
       "3                    18.0              63.00                    0   \n",
       "4                    18.0              63.00                    1   \n",
       "...                   ...                ...                  ...   \n",
       "509231              170.9             747.45                    0   \n",
       "509232              170.9             747.45                    0   \n",
       "509233              170.9             747.45                    0   \n",
       "509234              170.9             747.45                    0   \n",
       "509235              170.9             747.45                    0   \n",
       "\n",
       "        greater_than_75  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "...                 ...  \n",
       "509231                0  \n",
       "509232                0  \n",
       "509233                0  \n",
       "509234                0  \n",
       "509235                0  \n",
       "\n",
       "[509236 rows x 18 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eluvio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the relation between up_votes and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_list = ['01','02','03','04','05','06','07','08','09','10','11','12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_by_month = {}\n",
    "for year in range(2008,2016):\n",
    "    if year == 2008:\n",
    "        votes_this_year = votes[0:year_index['2008']]\n",
    "        dates_this_year = dates[0:year_index['2008']]\n",
    "    else:\n",
    "        votes_this_year = votes[year_index[str(year-1)]:year_index[str(year)]]\n",
    "        dates_this_year = dates[year_index[str(year-1)]:year_index[str(year)]]\n",
    "    month_this_year = []\n",
    "    for i in range(len(dates_this_year)):\n",
    "        month_this_year.append(dates_this_year[i][5:7])\n",
    "    month_this_year_index = []  \n",
    "    for month in month_list:\n",
    "        month_this_year_index.append(month_this_year.index(month))\n",
    "    for i in range(len(month_list)):\n",
    "        if i<11:\n",
    "            vote_by_month[str(year)+'-'+month_list[i]] = statistics.mean(votes_this_year[month_this_year_index[i]:month_this_year_index[i+1]])\n",
    "        else:\n",
    "            vote_by_month[str(year)+'-'+month_list[i]] = statistics.mean(votes_this_year[month_this_year_index[i]:len(votes_this_year)])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(*zip(*sorted(vote_by_month.items())), 'bo')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Mean up votes')\n",
    "plt.title(\"Mean up votes VS Month\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The results shows that the up_votes of videos increases significantly with time, \n",
    "#therefore we need to consider about the posted year of the video in our prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the relation between up_votes and author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_author_indexes = {}\n",
    "for i in range(len(author_list)):\n",
    "    if author_list[i] not in dict_author_indexes:\n",
    "        dict_author_indexes[author_list[i]] = [i]\n",
    "    else:\n",
    "        dict_author_indexes[author_list[i]].append(i)\n",
    "dict_author_number = {}\n",
    "for author in author_list:\n",
    "    if author not in dict_author_number:\n",
    "        dict_author_number[author] = 1\n",
    "    else:\n",
    "        dict_author_number[author] = dict_author_number[author]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_author_vote = {}\n",
    "for author in dict_author_indexes:\n",
    "    his_votes = []\n",
    "    for index in dict_author_indexes[author]:\n",
    "        his_votes.append(votes[index])\n",
    "    dict_author_vote[author] = his_votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_list = []\n",
    "median_list = []\n",
    "mean_list = []\n",
    "for author in dict_author_indexes:\n",
    "    number_list.append(len(dict_author_vote[author]))\n",
    "    median_list.append(statistics.median(dict_author_vote[author]))\n",
    "    mean_list.append(statistics.mean(dict_author_vote[author]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between the median upvotes number and the number of posted video for an author is: -0.013832341806825195\n",
      "The correlation between the mean upvotes number and the number of posted video for an author is: -0.002423070043245237\n"
     ]
    }
   ],
   "source": [
    "corr, p_value = scipy.stats.pearsonr(number_list, median_list)\n",
    "print('The correlation between the median upvotes number and the number of posted video for an author is: '+ str(corr))\n",
    "corr, p_value = scipy.stats.pearsonr(number_list, mean_list)\n",
    "print('The correlation between the mean upvotes number and the number of posted video for an author is: '+ str(corr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The results shows very week correlations between up_votes of videos and the author, \n",
    "#therefore we don't need to consider about the author of the video in our prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model to predict whether a video has more upvotes than at 75% of the videos in that year, using the lemmatized tokens in the titles as features, implementing Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function to tokenize, lemmatize and remove noise for each video title. \n",
    "#The returened list contains the extracted key words for each input title.\n",
    "def remove_noise(tweet_tokens, stop_words = ()):\n",
    "\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    for token, tag in pos_tag(tweet_tokens):\n",
    "        token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
    "                       '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', token)\n",
    "        token = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", token)\n",
    "        token = re.sub(\"'s\",\"\", token)\n",
    "        token = re.sub(\"‘\",\"\", token)\n",
    "        token = re.sub(\"’\",\"\", token)\n",
    "        token = re.sub(\"”\",\"\", token)\n",
    "        token = re.sub(\"-\",\"\", token)\n",
    "        token = re.sub(\"–\",\"\", token)\n",
    "        token = re.sub(\"--\",\"\", token)\n",
    "        token_u = (token.encode('unicode-escape')).decode(\"utf-8\", \"strict\")\n",
    "        if r'\\u200b' in token_u:\n",
    "            token = token_u.split('\\\\u200b')[1]\n",
    "        if token.isnumeric():\n",
    "            token = re.sub(token,\"\", token)\n",
    "        if 'http' in token or 'http' in token or 'html' in token or 'www.' in token:\n",
    "            token = re.sub(token,\"\", token)\n",
    "        if token == 'us':\n",
    "            token = re.sub(token,\"\", token)\n",
    "            \n",
    "\n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "\n",
    "        if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words and token.lower() != \"say\":\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify the video to two sets: \n",
    "#with more upvotes than 75% of the video in its year; with less or equal upvotes than 75% of the video in its year\n",
    "df_positive = eluvio[eluvio['greater_than_75']==1]\n",
    "df_negative = eluvio[eluvio['greater_than_75']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_titles = list(df_positive['title'])\n",
    "neg_titles = list(df_negative['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cleaned_tokens_list = []\n",
    "for i in range(0,len(pos_titles)):\n",
    "    the_title = nltk.word_tokenize(pos_titles[i])\n",
    "    positive_cleaned_tokens_list.append(remove_noise(the_title, stop_words))\n",
    "positive_cleaned_tokens_list = positive_cleaned_tokens_list.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_cleaned_tokens_list = []\n",
    "for i in range(0,len(neg_titles)):\n",
    "    the_title = nltk.word_tokenize(neg_titles[i])\n",
    "    negative_cleaned_tokens_list.append(remove_noise(the_title, stop_words))\n",
    "negative_cleaned_tokens_list = negative_cleaned_tokens_list.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tokens_list = []\n",
    "for i in range(0,len(titles)):\n",
    "    the_title = nltk.word_tokenize(titles[i])\n",
    "    cleaned_tokens_list.append(remove_noise(the_title, stop_words))\n",
    "cleaned_tokens_list = cleaned_tokens_list.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_words(cleaned_tokens_list):\n",
    "    for tokens in cleaned_tokens_list:\n",
    "        for token in tokens:\n",
    "            yield token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = get_all_words(cleaned_tokens_list)\n",
    "freq_dist = FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(freq_dist.keys())\n",
    "#list(freq_dist.values())\n",
    "#print(freq_dist.most_common(20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keep the words appear more than 10 times in the entire datasets as the features\n",
    "common_words = []\n",
    "for i in range(len(list(freq_dist.keys()))):\n",
    "    if list(freq_dist.values())[i] > 10:\n",
    "        common_words.append(list(freq_dist.keys())[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19887"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    return list(set(lst1) & set(lst2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cleaned_tokens_list_use = []\n",
    "for i in range(len(positive_cleaned_tokens_list)):\n",
    "    positive_cleaned_tokens_list_use.append(intersection(positive_cleaned_tokens_list[i],common_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_cleaned_tokens_list_use = []\n",
    "for i in range(len(negative_cleaned_tokens_list)):\n",
    "    negative_cleaned_tokens_list_use.append(intersection(negative_cleaned_tokens_list[i],common_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_model(cleaned_tokens_list):\n",
    "    for tokens in cleaned_tokens_list:\n",
    "        yield dict([token, True] for token in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tokens_for_model = prepare_for_model(positive_cleaned_tokens_list_use)\n",
    "negative_tokens_for_model = prepare_for_model(negative_cleaned_tokens_list_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_dataset = [(dic, \"Positive\")\n",
    "                     for dic in positive_tokens_for_model]\n",
    "\n",
    "negative_dataset = [(dic, \"Negative\")\n",
    "                     for dic in negative_tokens_for_model]\n",
    "\n",
    "dataset = positive_dataset + negative_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly split the data into 90% training set and 10% test set\n",
    "import random\n",
    "random.shuffle(dataset)\n",
    "\n",
    "train_data = dataset[:int(len(titles)*0.9)]\n",
    "test_data = dataset[int(len(titles)*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import classify\n",
    "from nltk import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.580924514963475\n",
      "Most Informative Features\n",
      "          neonicotinoids = True           Positi : Negati =     21.5 : 1.0\n",
      "               falkvinge = True           Positi : Negati =     17.8 : 1.0\n",
      "             enslavement = True           Positi : Negati =     17.8 : 1.0\n",
      "            unvaccinated = True           Positi : Negati =     16.6 : 1.0\n",
      "                itartass = True           Negati : Positi =     15.7 : 1.0\n",
      "                covertly = True           Positi : Negati =     15.4 : 1.0\n",
      "                    mpaa = True           Positi : Negati =     13.6 : 1.0\n",
      "                    teem = True           Positi : Negati =     12.9 : 1.0\n",
      "                 presstv = True           Negati : Positi =     12.7 : 1.0\n",
      "                  stored = True           Positi : Negati =     11.7 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#use naive Bayes to train the model, the accuracy is about 58% for most of the tests\n",
    "classifier = NaiveBayesClassifier.train(train_data)\n",
    "\n",
    "print(\"Accuracy is:\", classify.accuracy(classifier, test_data))\n",
    "\n",
    "print(classifier.show_most_informative_features(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To check which countries are mentioned in which titles and to compare which countries are mentioned more frequently, I built a list of country name/ nationality name keywords to extract the countries correctly. For the countries US and UK, the extraction involves additional procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_countries = []\n",
    "short_countries = []\n",
    "for country in pycountry.countries:\n",
    "    if ' ' in country.name:\n",
    "        long_countries.append(country.name)\n",
    "    else:\n",
    "        short_countries.append(country.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "NATIONALITIES_list = ['Afghan', 'Albanian', 'Algerian', 'American', 'Andorran', 'Angolan', 'Antiguans', 'Argentinean', 'Armenian', 'Australian', 'Austrian', 'Azerbaijani', 'Bahamian', 'Bahraini', 'Bangladeshi', 'Barbadian', 'Barbudans', 'Batswana', 'Belarusian', 'Belgian', 'Belizean', 'Beninese', 'Bhutanese', 'Bolivian', 'Bosnian', 'Brazilian', 'British', 'Bruneian', 'Bulgarian', 'Burkinabe', 'Burmese', 'Burundian', 'Cambodian', 'Cameroonian', 'Canadian', 'Cape Verdean', 'Central African', 'Chadian', 'Chilean', 'Chinese', 'Colombian', 'Comoran',  'Congolese', 'Costa Rican', 'Croatian', 'Cuban', 'Cypriot', 'Czech', 'Danish', 'Djibouti', 'Dominican', 'Dutch', 'Dutchman', 'Dutchwoman', 'East Timorese', 'Ecuadorean', 'Egyptian', 'Emirian', 'Equatorial Guinean', 'Eritrean', 'Estonian', 'Ethiopian', 'Fijian', 'Filipino', 'Finnish', 'French', 'Gabonese', 'Gambian', 'Georgian', 'German', 'Ghanaian', 'Greek', 'Grenadian', 'Guatemalan', 'Guinea-Bissauan', 'Guinean', 'Guyanese', 'Haitian', 'Herzegovinian', 'Honduran', 'Hungarian', 'I-Kiribati', 'Icelander', 'Indian', 'Indonesian', 'Iranian', 'Iraqi', 'Irish', 'Israeli', 'Italian', 'Ivorian', 'Jamaican', 'Japanese', 'Jordanian', 'Kazakhstani', 'Kenyan', 'Kittian and Nevisian', 'Kuwaiti', 'Kyrgyz', 'Laotian', 'Latvian', 'Lebanese', 'Liberian', 'Libyan', 'Liechtensteiner', 'Lithuanian', 'Luxembourger', 'Macedonian', 'Malagasy', 'Malawian', 'Malaysian', 'Maldivan', 'Malian', 'Maltese', 'Marshallese', 'Mauritanian', 'Mauritian', 'Mexican', 'Micronesian', 'Moldovan', 'Monacan', 'Mongolian', 'Moroccan', 'Mosotho', 'Motswana', 'Mozambican', 'Namibian', 'Nauruan', 'Nepalese', 'Netherlander', 'New Zealander', 'Ni-Vanuatu', 'Nicaraguan', 'Nigerian', 'Nigerien', 'North Korean', 'Northern Irish', 'Norwegian', 'Omani', 'Pakistani', 'Palauan', 'Panamanian', 'Papua New Guinean', 'Paraguayan', 'Peruvian', 'Polish', 'Portuguese', 'Qatari', 'Romanian', 'Russian', 'Rwandan', 'Saint Lucian', 'Salvadoran', 'Samoan', 'San Marinese', 'Sao Tomean', 'Saudi', 'Scottish', 'Senegalese', 'Serbian', 'Seychellois', 'Sierra Leonean', 'Singaporean', 'Slovakian', 'Slovenian', 'Solomon Islander', 'Somali', 'South African', 'South Korean', 'Spanish', 'Sri Lankan', 'Sudanese', 'Surinamer', 'Swazi', 'Swedish', 'Swiss', 'Syrian', 'Taiwanese', 'Tajik', 'Tanzanian', 'Thai', 'Togolese', 'Tongan', 'Trinidadian or Tobagonian', 'Tunisian', 'Turkish', 'Tuvaluan', 'Ugandan', 'Ukrainian', 'Uruguayan', 'Uzbekistani', 'Venezuelan', 'Vietnamese', 'Welsh', 'Yemenite', 'Zambian', 'Zimbabwean']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import country_converter as coco\n",
    "standard_names = coco.convert(names=long_countries, to='name_short')\n",
    "same_after_coco = []\n",
    "diff_after_coco = []\n",
    "diff_after_coco_long = []\n",
    "for i in range(len(standard_names)):\n",
    "    if standard_names[i] == long_countries[i]:\n",
    "        same_after_coco.append(standard_names[i])\n",
    "    else:\n",
    "        diff_after_coco.append(standard_names[i])\n",
    "        diff_after_coco_long.append(long_countries[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = []\n",
    "for country in short_countries:\n",
    "    country_l = [country]\n",
    "    for nationality in NATIONALITIES_list:\n",
    "        if country[:4] == nationality[:4]:\n",
    "            country_l.append(nationality)\n",
    "    countries.append(country_l)\n",
    "countries[9] = ['Australia', 'Australian']\n",
    "countries[10] = ['Austria', 'Austrian']\n",
    "countries[23] = ['Switzerland', 'Swiss']\n",
    "countries[27] = ['Barbados', 'Barbadian']\n",
    "countries[41] = ['Denmark', 'Danish']\n",
    "countries[46] = ['Spain', 'Spanish']\n",
    "countries[49] =  ['Finland', 'Finnish']\n",
    "countries[51] =  ['France', 'French']\n",
    "countries[57] =   ['Guinea', 'Guinean']\n",
    "countries[60] =   ['Guinea-Bissau', 'Guinea-Bissauan']\n",
    "countries[73] =   ['Ireland','Irish']\n",
    "countries[96] =  ['Macao', 'Macau']\n",
    "countries[108] =  ['Mauritania', 'Mauritanian']\n",
    "countries[111] =  ['Mauritius', 'Mauritian']\n",
    "countries[112] =  ['Malawi', 'Malawian']\n",
    "countries[113] =  ['Malaysia', 'Malaysian']\n",
    "countries[116] =  ['Niger', 'Nigerien']\n",
    "countries[117] =  ['Nigeria', 'Nigerian']\n",
    "countries[120] =  ['Netherlands', 'Netherlander','Holland','Dutch']\n",
    "countries[131] =  ['Poland','Polish']\n",
    "countries[144] =  ['Slovakia', 'Slovakian']\n",
    "countries[145] =  ['Slovenia', 'Slovenian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_countries = []\n",
    "for i in range(len(diff_after_coco)):\n",
    "    country = diff_after_coco[i]\n",
    "    country_long = diff_after_coco_long[i]\n",
    "    country_l = [country, country_long]\n",
    "    if ' ' not in country:\n",
    "        for nationality in NATIONALITIES_list:\n",
    "            if country[:4] == nationality[:4]:\n",
    "                country_l.append(nationality)\n",
    "    other_countries.append(country_l)\n",
    "other_countries[12] =  ['South Korea', 'Korea, Republic of', 'South Korean', 'S. Korea', 'SKorea', 'S.Korea', 'S Korea', ]\n",
    "other_countries[13] =  ['Laos', \"Lao People's Democratic Republic\", 'Laotian']\n",
    "other_countries[18] =  ['North Korea', \"Korea, Democratic People's Republic of\", 'North Korean', 'N. Korea', 'NKorea', 'N.Korea', 'N Korea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in same_after_coco:\n",
    "    country_l = [country]\n",
    "    other_countries.append(country_l)\n",
    "other_countries[36] = ['United Arab Emirates', 'UAE', 'U.A.E']\n",
    "other_countries[44] = ['Central African Republic','Central African']\n",
    "other_countries[48] = ['Costa Rica', 'Costa Rican']\n",
    "other_countries[51] = ['Dominican Republic', 'Dominican']\n",
    "other_countries[53] = ['United Kingdom', 'British', 'U.K', 'Britain', '(UK)', '[UK]']\n",
    "other_countries[59] = ['Sri Lanka', 'Sri Lankan']\n",
    "other_countries[64] = ['New Zealand', 'New Zealander']\n",
    "other_countries[70] = ['Sierra Leone', 'Sierra Leonean']\n",
    "other_countries[78] = ['United States', 'U.S.A', 'U.S', '(US)', '(USA)', '[US]', '[USA]']\n",
    "other_countries[79] = ['South Africa', 'South African']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_countries = countries + other_countries + [['Korea']]\n",
    "for i in range(len(all_countries)):\n",
    "    all_countries[i].append(all_countries[i][0].upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Aruba', 'ARUBA'],\n",
       " ['Afghanistan', 'Afghan', 'AFGHANISTAN'],\n",
       " ['Angola', 'Angolan', 'ANGOLA'],\n",
       " ['Anguilla', 'ANGUILLA'],\n",
       " ['Albania', 'Albanian', 'ALBANIA'],\n",
       " ['Andorra', 'Andorran', 'ANDORRA'],\n",
       " ['Argentina', 'Argentinean', 'ARGENTINA'],\n",
       " ['Armenia', 'Armenian', 'ARMENIA'],\n",
       " ['Antarctica', 'ANTARCTICA'],\n",
       " ['Australia', 'Australian', 'AUSTRALIA']]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the country name/ nationality name list has been built\n",
    "all_countries[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the contained countries for all titles in the dataset; count the number of appearance for each country\n",
    "country_by_title = []\n",
    "country_count = {}\n",
    "for title in titles:\n",
    "    contain = []\n",
    "    for country in all_countries:\n",
    "        for name in country:\n",
    "            if name in title:\n",
    "                contain.append(country[0])\n",
    "                if country[0] not in country_count:\n",
    "                    country_count[country[0]] = 1\n",
    "                else:\n",
    "                    country_count[country[0]] = country_count[country[0]] + 1\n",
    "                break\n",
    "    country_by_title.append(contain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(titles)):\n",
    "    if 'US' in titles[i]:\n",
    "        if 'United States' not in country_by_title[i]:\n",
    "            title_l = titles[i].split()\n",
    "            if 'US' not in title_l and 'USA' not in title_l:\n",
    "                not_US = True\n",
    "                for word in title_l:\n",
    "                    if bool(re.match(\"US[-/.?:,!;]+\", word)) or bool(re.match(\"USA[-/.?:,!;]+\", word)):\n",
    "                        not_US = False\n",
    "                if not_US == False:\n",
    "                    country_by_title[i].append('United States')\n",
    "                    country_count['United States'] = country_count['United States'] + 1\n",
    "            else:\n",
    "                country_by_title[i].append('United States')\n",
    "                country_count['United States'] = country_count['United States'] + 1\n",
    "    if 'UK' in titles[i]:\n",
    "        if 'United Kingdom' not in country_by_title[i]:\n",
    "            title_l = titles[i].split()\n",
    "            if 'UK' not in title_l:\n",
    "                not_UK = True\n",
    "                for word in title_l:\n",
    "                    if bool(re.match(\"UK[-/.?:,!;]+\", word)):\n",
    "                        not_UK = False\n",
    "                if not_UK == False:\n",
    "                    country_by_title[i].append('United Kingdom')\n",
    "                    country_count['United Kingdom'] = country_count['United Kingdom'] + 1\n",
    "            else:\n",
    "                country_by_title[i].append('United Kingdom')\n",
    "                country_count['United Kingdom'] = country_count['United Kingdom'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Pakistan'],\n",
       " ['Japan'],\n",
       " ['Egypt', 'United States'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['Poland', 'Ukraine'],\n",
       " [],\n",
       " [],\n",
       " ['Poland', 'United States']]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_by_title[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('United States', 40290), ('China', 30723), ('Russia', 29387), ('Syria', 27715), ('Israel', 23538), ('United Kingdom', 21421), ('Iran', 18272), ('India', 14420), ('Korea', 13523), ('Ukraine', 12086), ('France', 11718), ('Turkey', 11583), ('Iraq', 11099), ('Egypt', 11000), ('Germany', 10997), ('Japan', 10497), ('Pakistan', 10279), ('North Korea', 9695), ('Australia', 8855), ('Afghanistan', 8153), ('Canada', 7645), ('Libya', 5740), ('Mexico', 5675), ('Greece', 5194), ('Venezuela', 4693), ('Yemen', 4437), ('South Korea', 4344), ('Turkmenistan', 4243), ('Brazil', 4189), ('Italy', 4189), ('Niger', 3971), ('Spain', 3813), ('Nigeria', 3681), ('Saudi Arabia', 3558), ('Netherlands', 2870), ('Indonesia', 2721), ('Greenland', 2679), ('Malaysia', 2645), ('Thailand', 2451), ('Ireland', 2426), ('South Africa', 2404), ('Sweden', 2368), ('Lebanon', 2291), ('Somalia', 2244), ('Philippines', 2208), ('Sudan', 2157), ('Cuba', 1986), ('Hong Kong', 1983), ('Kenya', 1889), ('Norway', 1869), ('Bangladesh', 1863), ('Switzerland', 1840), ('Poland', 1780), ('Colombia', 1632), ('Mali', 1599), ('New Zealand', 1518), ('Taiwan', 1463), ('Myanmar', 1432), ('Belgium', 1421), ('Jordan', 1406), ('Vatican', 1367), ('Tunisia', 1353), ('Vietnam', 1342), ('Zimbabwe', 1292), ('Argentina', 1236), ('Sri Lanka', 1186), ('Haiti', 1163), ('Bahrain', 1141), ('Denmark', 1104), ('Chile', 1075), ('Congo', 1053), ('Iceland', 1046), ('South Sudan', 1040), ('Qatar', 1038), ('Nepal', 1027), ('Hungary', 1006), ('Palestine', 963), ('Georgia', 953), ('Uganda', 910), ('Ecuador', 896), ('Austria', 896), ('Peru', 831), ('Singapore', 805), ('United Arab Emirates', 791), ('Armenia', 736), ('Romania', 670), ('Panama', 664), ('Algeria', 663), ('Cyprus', 659), ('Ethiopia', 649), ('Guinea', 625), ('Cambodia', 622), ('Bolivia', 621), ('Finland', 615), ('Liberia', 612), ('Honduras', 603), ('Czechia', 601), ('Serbia', 583), ('Central African Republic', 574), ('Morocco', 573), ('Guatemala', 567), ('Bulgaria', 556), ('Kuwait', 532), ('Portugal', 513), ('Sierra Leone', 448), ('Rwanda', 419), ('Belarus', 398), ('Croatia', 383), ('Azerbaijan', 371), ('Uruguay', 369), ('Burundi', 312), ('Tanzania', 309), ('Kyrgyzstan', 308), ('Nicaragua', 306), ('Cameroon', 304), ('Lithuania', 289), ('Chad', 267), ('Kazakhstan', 266), ('El Salvador', 265), ('Macedonia', 263), ('Estonia', 260), ('Antarctica', 251), ('Papua New Guinea', 247), ('Latvia', 246), ('Maldives', 233), ('Ghana', 233), ('Costa Rica', 232), ('Burkina Faso', 228), ('Jamaica', 222), ('Moldova', 219), ('Fiji', 205), ('Albania', 194), ('DR Congo', 191), ('Senegal', 189), ('Mozambique', 185), ('Puerto Rico', 180), ('Mongolia', 178), ('Paraguay', 177), ('Dominica', 170), ('Malawi', 170), ('Madagascar', 169), ('Eritrea', 169), ('Oman', 166), ('Malta', 159), ('Dominican Republic', 159), ('Gambia', 158), ('Uzbekistan', 146), ('Angola', 143), ('Slovenia', 142), ('Zambia', 141), ('Tajikistan', 138), ('Luxembourg', 136), ('Laos', 131), ('Nauru', 131), ('Gibraltar', 127), ('Slovakia', 125), ('Vanuatu', 104), ('Montenegro', 103), ('Mauritania', 101), ('Guam', 94)]\n"
     ]
    }
   ],
   "source": [
    "sorted_countries = sorted(country_count.items(), key=lambda kv: kv[1], reverse=True)\n",
    "print(sorted_countries[:(int(len(sorted_countries)*0.70))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_count_year = {}\n",
    "for year_number in range(2008,2017):\n",
    "    year = str(year_number)\n",
    "    country_count_year[year] = {}\n",
    "    for i in range(year_index_dict[year][0],year_index_dict[year][1]):\n",
    "        contained = country_by_title[i]\n",
    "        for country in contained:\n",
    "            if country not in country_count_year[year]:\n",
    "                country_count_year[year][country] = 1\n",
    "            else:\n",
    "                country_count_year[year][country] = country_count_year[year][country] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(United States, 2189)</td>\n",
       "      <td>(Israel, 2300)</td>\n",
       "      <td>(Israel, 2181)</td>\n",
       "      <td>(Libya, 2702)</td>\n",
       "      <td>(Syria, 3652)</td>\n",
       "      <td>(Syria, 7271)</td>\n",
       "      <td>(Russia, 8806)</td>\n",
       "      <td>(United States, 7923)</td>\n",
       "      <td>(United States, 7157)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(United Kingdom, 1136)</td>\n",
       "      <td>(United States, 1719)</td>\n",
       "      <td>(United States, 1701)</td>\n",
       "      <td>(Egypt, 2362)</td>\n",
       "      <td>(China, 2894)</td>\n",
       "      <td>(United States, 6982)</td>\n",
       "      <td>(Ukraine, 8121)</td>\n",
       "      <td>(Russia, 7393)</td>\n",
       "      <td>(China, 6065)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(China, 1111)</td>\n",
       "      <td>(Iran, 1649)</td>\n",
       "      <td>(United Kingdom, 1308)</td>\n",
       "      <td>(United States, 1942)</td>\n",
       "      <td>(United States, 2562)</td>\n",
       "      <td>(China, 5688)</td>\n",
       "      <td>(United States, 8115)</td>\n",
       "      <td>(China, 5801)</td>\n",
       "      <td>(Russia, 4942)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Israel, 1055)</td>\n",
       "      <td>(United Kingdom, 1230)</td>\n",
       "      <td>(China, 1228)</td>\n",
       "      <td>(Syria, 1924)</td>\n",
       "      <td>(Iran, 2447)</td>\n",
       "      <td>(United Kingdom, 3647)</td>\n",
       "      <td>(China, 5140)</td>\n",
       "      <td>(Syria, 5490)</td>\n",
       "      <td>(Syria, 4874)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Iraq, 1046)</td>\n",
       "      <td>(China, 888)</td>\n",
       "      <td>(Iran, 1143)</td>\n",
       "      <td>(China, 1908)</td>\n",
       "      <td>(Israel, 1897)</td>\n",
       "      <td>(Russia, 3515)</td>\n",
       "      <td>(Israel, 4971)</td>\n",
       "      <td>(Israel, 3908)</td>\n",
       "      <td>(United Kingdom, 3883)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Russia, 1025)</td>\n",
       "      <td>(Afghanistan, 586)</td>\n",
       "      <td>(Afghanistan, 881)</td>\n",
       "      <td>(Japan, 1693)</td>\n",
       "      <td>(United Kingdom, 1689)</td>\n",
       "      <td>(Korea, 3477)</td>\n",
       "      <td>(Syria, 4234)</td>\n",
       "      <td>(United Kingdom, 3490)</td>\n",
       "      <td>(Turkey, 3653)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Iran, 839)</td>\n",
       "      <td>(Korea, 554)</td>\n",
       "      <td>(Korea, 736)</td>\n",
       "      <td>(Israel, 1663)</td>\n",
       "      <td>(Russia, 1579)</td>\n",
       "      <td>(Israel, 3140)</td>\n",
       "      <td>(United Kingdom, 3547)</td>\n",
       "      <td>(Iran, 3392)</td>\n",
       "      <td>(India, 3037)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Pakistan, 647)</td>\n",
       "      <td>(Pakistan, 552)</td>\n",
       "      <td>(Russia, 720)</td>\n",
       "      <td>(United Kingdom, 1491)</td>\n",
       "      <td>(Egypt, 1363)</td>\n",
       "      <td>(India, 2890)</td>\n",
       "      <td>(Iraq, 3389)</td>\n",
       "      <td>(Turkey, 2896)</td>\n",
       "      <td>(Korea, 2745)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Georgia, 514)</td>\n",
       "      <td>(Russia, 545)</td>\n",
       "      <td>(Pakistan, 600)</td>\n",
       "      <td>(Iran, 1357)</td>\n",
       "      <td>(France, 1201)</td>\n",
       "      <td>(Iran, 2877)</td>\n",
       "      <td>(India, 2453)</td>\n",
       "      <td>(India, 2754)</td>\n",
       "      <td>(Israel, 2423)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(India, 485)</td>\n",
       "      <td>(Iraq, 504)</td>\n",
       "      <td>(Germany, 588)</td>\n",
       "      <td>(Pakistan, 911)</td>\n",
       "      <td>(India, 1196)</td>\n",
       "      <td>(Egypt, 2830)</td>\n",
       "      <td>(Iran, 2343)</td>\n",
       "      <td>(France, 2740)</td>\n",
       "      <td>(Iran, 2225)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(Afghanistan, 457)</td>\n",
       "      <td>(North Korea, 451)</td>\n",
       "      <td>(North Korea, 511)</td>\n",
       "      <td>(Russia, 862)</td>\n",
       "      <td>(Korea, 1043)</td>\n",
       "      <td>(North Korea, 2703)</td>\n",
       "      <td>(Korea, 2338)</td>\n",
       "      <td>(Ukraine, 2548)</td>\n",
       "      <td>(Germany, 2171)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(Zimbabwe, 353)</td>\n",
       "      <td>(India, 433)</td>\n",
       "      <td>(Haiti, 481)</td>\n",
       "      <td>(Germany, 841)</td>\n",
       "      <td>(Japan, 1008)</td>\n",
       "      <td>(France, 2140)</td>\n",
       "      <td>(Turkey, 1831)</td>\n",
       "      <td>(Germany, 2512)</td>\n",
       "      <td>(France, 2131)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(Germany, 293)</td>\n",
       "      <td>(France, 337)</td>\n",
       "      <td>(India, 469)</td>\n",
       "      <td>(France, 821)</td>\n",
       "      <td>(Pakistan, 966)</td>\n",
       "      <td>(Japan, 1951)</td>\n",
       "      <td>(Australia, 1823)</td>\n",
       "      <td>(Iraq, 2212)</td>\n",
       "      <td>(North Korea, 2016)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(France, 267)</td>\n",
       "      <td>(Mexico, 320)</td>\n",
       "      <td>(Iraq, 458)</td>\n",
       "      <td>(India, 703)</td>\n",
       "      <td>(Germany, 958)</td>\n",
       "      <td>(Pakistan, 1778)</td>\n",
       "      <td>(Japan, 1733)</td>\n",
       "      <td>(Australia, 1931)</td>\n",
       "      <td>(Iraq, 1777)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(Japan, 234)</td>\n",
       "      <td>(Germany, 316)</td>\n",
       "      <td>(France, 444)</td>\n",
       "      <td>(Afghanistan, 624)</td>\n",
       "      <td>(Afghanistan, 910)</td>\n",
       "      <td>(Germany, 1619)</td>\n",
       "      <td>(Germany, 1699)</td>\n",
       "      <td>(Greece, 1930)</td>\n",
       "      <td>(Pakistan, 1667)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(Canada, 234)</td>\n",
       "      <td>(Australia, 307)</td>\n",
       "      <td>(Mexico, 399)</td>\n",
       "      <td>(Mexico, 584)</td>\n",
       "      <td>(Canada, 777)</td>\n",
       "      <td>(Australia, 1567)</td>\n",
       "      <td>(France, 1637)</td>\n",
       "      <td>(Korea, 1901)</td>\n",
       "      <td>(Australia, 1643)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(Korea, 220)</td>\n",
       "      <td>(Canada, 241)</td>\n",
       "      <td>(Australia, 353)</td>\n",
       "      <td>(Greece, 575)</td>\n",
       "      <td>(Greece, 758)</td>\n",
       "      <td>(Turkey, 1425)</td>\n",
       "      <td>(Pakistan, 1610)</td>\n",
       "      <td>(Yemen, 1838)</td>\n",
       "      <td>(Japan, 1606)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(Somalia, 192)</td>\n",
       "      <td>(Somalia, 232)</td>\n",
       "      <td>(Turkey, 302)</td>\n",
       "      <td>(Turkey, 564)</td>\n",
       "      <td>(North Korea, 757)</td>\n",
       "      <td>(Canada, 1392)</td>\n",
       "      <td>(North Korea, 1562)</td>\n",
       "      <td>(Japan, 1794)</td>\n",
       "      <td>(Canada, 1294)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(Mexico, 190)</td>\n",
       "      <td>(Honduras, 227)</td>\n",
       "      <td>(South Korea, 279)</td>\n",
       "      <td>(Yemen, 550)</td>\n",
       "      <td>(Mexico, 755)</td>\n",
       "      <td>(Afghanistan, 1191)</td>\n",
       "      <td>(Egypt, 1405)</td>\n",
       "      <td>(Canada, 1652)</td>\n",
       "      <td>(Turkmenistan, 1191)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(Australia, 158)</td>\n",
       "      <td>(Sri Lanka, 225)</td>\n",
       "      <td>(Canada, 278)</td>\n",
       "      <td>(Korea, 509)</td>\n",
       "      <td>(Turkey, 699)</td>\n",
       "      <td>(Brazil, 991)</td>\n",
       "      <td>(Canada, 1381)</td>\n",
       "      <td>(Egypt, 1580)</td>\n",
       "      <td>(Afghanistan, 1063)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      2008                    2009                    2010  \\\n",
       "0    (United States, 2189)          (Israel, 2300)          (Israel, 2181)   \n",
       "1   (United Kingdom, 1136)   (United States, 1719)   (United States, 1701)   \n",
       "2            (China, 1111)            (Iran, 1649)  (United Kingdom, 1308)   \n",
       "3           (Israel, 1055)  (United Kingdom, 1230)           (China, 1228)   \n",
       "4             (Iraq, 1046)            (China, 888)            (Iran, 1143)   \n",
       "5           (Russia, 1025)      (Afghanistan, 586)      (Afghanistan, 881)   \n",
       "6              (Iran, 839)            (Korea, 554)            (Korea, 736)   \n",
       "7          (Pakistan, 647)         (Pakistan, 552)           (Russia, 720)   \n",
       "8           (Georgia, 514)           (Russia, 545)         (Pakistan, 600)   \n",
       "9             (India, 485)             (Iraq, 504)          (Germany, 588)   \n",
       "10      (Afghanistan, 457)      (North Korea, 451)      (North Korea, 511)   \n",
       "11         (Zimbabwe, 353)            (India, 433)            (Haiti, 481)   \n",
       "12          (Germany, 293)           (France, 337)            (India, 469)   \n",
       "13           (France, 267)           (Mexico, 320)             (Iraq, 458)   \n",
       "14            (Japan, 234)          (Germany, 316)           (France, 444)   \n",
       "15           (Canada, 234)        (Australia, 307)           (Mexico, 399)   \n",
       "16            (Korea, 220)           (Canada, 241)        (Australia, 353)   \n",
       "17          (Somalia, 192)          (Somalia, 232)           (Turkey, 302)   \n",
       "18           (Mexico, 190)         (Honduras, 227)      (South Korea, 279)   \n",
       "19        (Australia, 158)        (Sri Lanka, 225)           (Canada, 278)   \n",
       "\n",
       "                      2011                    2012                    2013  \\\n",
       "0            (Libya, 2702)           (Syria, 3652)           (Syria, 7271)   \n",
       "1            (Egypt, 2362)           (China, 2894)   (United States, 6982)   \n",
       "2    (United States, 1942)   (United States, 2562)           (China, 5688)   \n",
       "3            (Syria, 1924)            (Iran, 2447)  (United Kingdom, 3647)   \n",
       "4            (China, 1908)          (Israel, 1897)          (Russia, 3515)   \n",
       "5            (Japan, 1693)  (United Kingdom, 1689)           (Korea, 3477)   \n",
       "6           (Israel, 1663)          (Russia, 1579)          (Israel, 3140)   \n",
       "7   (United Kingdom, 1491)           (Egypt, 1363)           (India, 2890)   \n",
       "8             (Iran, 1357)          (France, 1201)            (Iran, 2877)   \n",
       "9          (Pakistan, 911)           (India, 1196)           (Egypt, 2830)   \n",
       "10           (Russia, 862)           (Korea, 1043)     (North Korea, 2703)   \n",
       "11          (Germany, 841)           (Japan, 1008)          (France, 2140)   \n",
       "12           (France, 821)         (Pakistan, 966)           (Japan, 1951)   \n",
       "13            (India, 703)          (Germany, 958)        (Pakistan, 1778)   \n",
       "14      (Afghanistan, 624)      (Afghanistan, 910)         (Germany, 1619)   \n",
       "15           (Mexico, 584)           (Canada, 777)       (Australia, 1567)   \n",
       "16           (Greece, 575)           (Greece, 758)          (Turkey, 1425)   \n",
       "17           (Turkey, 564)      (North Korea, 757)          (Canada, 1392)   \n",
       "18            (Yemen, 550)           (Mexico, 755)     (Afghanistan, 1191)   \n",
       "19            (Korea, 509)           (Turkey, 699)           (Brazil, 991)   \n",
       "\n",
       "                      2014                    2015                    2016  \n",
       "0           (Russia, 8806)   (United States, 7923)   (United States, 7157)  \n",
       "1          (Ukraine, 8121)          (Russia, 7393)           (China, 6065)  \n",
       "2    (United States, 8115)           (China, 5801)          (Russia, 4942)  \n",
       "3            (China, 5140)           (Syria, 5490)           (Syria, 4874)  \n",
       "4           (Israel, 4971)          (Israel, 3908)  (United Kingdom, 3883)  \n",
       "5            (Syria, 4234)  (United Kingdom, 3490)          (Turkey, 3653)  \n",
       "6   (United Kingdom, 3547)            (Iran, 3392)           (India, 3037)  \n",
       "7             (Iraq, 3389)          (Turkey, 2896)           (Korea, 2745)  \n",
       "8            (India, 2453)           (India, 2754)          (Israel, 2423)  \n",
       "9             (Iran, 2343)          (France, 2740)            (Iran, 2225)  \n",
       "10           (Korea, 2338)         (Ukraine, 2548)         (Germany, 2171)  \n",
       "11          (Turkey, 1831)         (Germany, 2512)          (France, 2131)  \n",
       "12       (Australia, 1823)            (Iraq, 2212)     (North Korea, 2016)  \n",
       "13           (Japan, 1733)       (Australia, 1931)            (Iraq, 1777)  \n",
       "14         (Germany, 1699)          (Greece, 1930)        (Pakistan, 1667)  \n",
       "15          (France, 1637)           (Korea, 1901)       (Australia, 1643)  \n",
       "16        (Pakistan, 1610)           (Yemen, 1838)           (Japan, 1606)  \n",
       "17     (North Korea, 1562)           (Japan, 1794)          (Canada, 1294)  \n",
       "18           (Egypt, 1405)          (Canada, 1652)    (Turkmenistan, 1191)  \n",
       "19          (Canada, 1381)           (Egypt, 1580)     (Afghanistan, 1063)  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The table shows the most-mentioned countries in each year\n",
    "df = pd.DataFrame()\n",
    "for year_number in range(2008,2017):\n",
    "    year = str(year_number)\n",
    "    sorted_years = sorted(country_count_year[year].items(), key=lambda kv: kv[1], reverse=True)[:50]\n",
    "    df[year] = sorted_years\n",
    "df[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model to predict whether a video has more upvotes than at 75% of the videos in that year, using the contained countries in the titles as features, implementing Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_sorted = sorted_countries[:(int(len(sorted_countries)*0.70))]\n",
    "major_countries = []\n",
    "for sorted_country in major_sorted:\n",
    "    major_countries.append(sorted_country[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "eluvio['contained_country'] =  country_by_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = eluvio[eluvio['greater_than_75']==1]\n",
    "df_negative = eluvio[eluvio['greater_than_75']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_country_by_title = list(df_positive['contained_country'])\n",
    "negative_country_by_title = list(df_negative['contained_country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_country_by_title_use = []\n",
    "for i in range(len(positive_country_by_title)):\n",
    "    l = intersection(positive_country_by_title[i], major_countries)\n",
    "    if l != []:\n",
    "        positive_country_by_title_use.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_country_by_title_use = []\n",
    "for i in range(len(negative_country_by_title)):\n",
    "    l = intersection(negative_country_by_title[i], major_countries)\n",
    "    if l != []:\n",
    "        negative_country_by_title_use.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tokens_for_model = prepare_for_model(positive_country_by_title_use)\n",
    "negative_tokens_for_model = prepare_for_model(negative_country_by_title_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_dataset = [(dic, \"Positive\")\n",
    "                     for dic in positive_tokens_for_model]\n",
    "\n",
    "negative_dataset = [(dic, \"Negative\")\n",
    "                     for dic in negative_tokens_for_model]\n",
    "\n",
    "dataset = positive_dataset + negative_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(dataset)\n",
    "\n",
    "train_data = dataset[:int(len(positive_country_by_title_use+negative_country_by_title_use)*.9)]\n",
    "test_data = dataset[int(len(positive_country_by_title_use+negative_country_by_title_use)*.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.7486863956875663\n",
      "Most Informative Features\n",
      "                 Burundi = True           Negati : Positi =      2.8 : 1.0\n",
      "                 Finland = True           Positi : Negati =      2.2 : 1.0\n",
      "             South Sudan = True           Negati : Positi =      2.2 : 1.0\n",
      "                 Iceland = True           Positi : Negati =      2.2 : 1.0\n",
      "                DR Congo = True           Negati : Positi =      2.1 : 1.0\n",
      "                 Myanmar = True           Negati : Positi =      2.0 : 1.0\n",
      "               Sri Lanka = True           Negati : Positi =      2.0 : 1.0\n",
      "                 Uruguay = True           Positi : Negati =      2.0 : 1.0\n",
      "                    Guam = True           Positi : Negati =      2.0 : 1.0\n",
      "               Lithuania = True           Positi : Negati =      2.0 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayesClassifier.train(train_data)\n",
    "\n",
    "print(\"Accuracy is:\", classify.accuracy(classifier, test_data))\n",
    "\n",
    "print(classifier.show_most_informative_features(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall, using the country names as features produces a model with better accuracy. (0.75 vs 0.58)\n",
    "# From the prediction result, we can see Finland and Iceland are the countries with the highest positive:negative ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering videos using the word stem of the tokens of the titles, implementing K-means method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "def stem(x):\n",
    "    dirty = word_tokenize(x)\n",
    "    tokens = []\n",
    "    for word in dirty:\n",
    "        if word.strip('.') == '':\n",
    "            pass\n",
    "        elif re.search(r'\\d{1,}', word):\n",
    "            pass\n",
    "        else:\n",
    "            tokens.append(word.strip('.'))\n",
    "    tokens = pos_tag(tokens)\n",
    "    stems = ' '.join(stemmer.stem(key.lower()) for key, value in  tokens if value != 'NNP')\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_stem = []\n",
    "for title in titles:\n",
    "    titles_stem.append(stem(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47550"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "stop_words = stopwords.words('english')\n",
    "#number_words = ['one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'zero', 'first', 'second', 'third']\n",
    "#common_words = ['hi', 'ha', 'wa', 'thi', 'whi']\n",
    "all_words = Counter()\n",
    "def count_everything(x):\n",
    "    x = x.split()\n",
    "    for word in x:\n",
    "        if word in stop_words or len(word) == 1 or word in string.punctuation+'--'+'||':\n",
    "            continue\n",
    "        all_words[word] += 1\n",
    "for item in titles_stem:\n",
    "    count_everything(item)\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwordsdf = pd.DataFrame(columns = ['words', 'count'])\n",
    "allwordsdf['count'] = pd.Series(list(all_words.values()))\n",
    "allwordsdf['words'] = pd.Series(list(all_words.keys()))\n",
    "allwordsdf.index = allwordsdf['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "nltkstems = [stemmer.stem(word) for word in words.words()]\n",
    "nltkwords = pd.DataFrame()\n",
    "nltkwords['words'] = nltkstems\n",
    "allwordsdf = allwordsdf[allwordsdf['words'].isin(nltkwords['words'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precinct</th>\n",
       "      <td>precinct</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ambival</th>\n",
       "      <td>ambival</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raptor</th>\n",
       "      <td>raptor</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gimmick</th>\n",
       "      <td>gimmick</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weasel</th>\n",
       "      <td>weasel</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parlor</th>\n",
       "      <td>parlor</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>graze</th>\n",
       "      <td>graze</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoom</th>\n",
       "      <td>zoom</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alarmist</th>\n",
       "      <td>alarmist</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stakehold</th>\n",
       "      <td>stakehold</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               words  count\n",
       "words                      \n",
       "precinct    precinct      8\n",
       "ambival      ambival      8\n",
       "raptor        raptor      8\n",
       "gimmick      gimmick      8\n",
       "weasel        weasel      8\n",
       "parlor        parlor      8\n",
       "graze          graze      8\n",
       "zoom            zoom      8\n",
       "alarmist    alarmist      8\n",
       "stakehold  stakehold      8"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allwordsdf[allwordsdf['count'] == allwordsdf['count'].quantile(.5)][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "stopwords = list(allwordsdf[(allwordsdf['count'] >= allwordsdf['count'].quantile(.995)) | (allwordsdf['count'] <= allwordsdf['count'].quantile(.5))]['words'])\n",
    "vecvocab = list(allwordsdf[(allwordsdf['count'] < allwordsdf['count'].quantile(.995)) & (allwordsdf['count'] > allwordsdf['count'].quantile(.5))]['words'])\n",
    "vec = TfidfVectorizer(stop_words = stopwords, vocabulary = vecvocab, tokenizer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8835"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vecvocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_matrix = vec.fit_transform(titles_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "pca = TruncatedSVD(n_components=100)\n",
    "vec_matrix_pca = pca.fit_transform(vec_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=10, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "clf10 = KMeans(n_clusters=10, verbose = 0)\n",
    "clf10.fit(vec_matrix_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_labels = clf10.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 6440,\n",
       " 1: 469429,\n",
       " 7: 4571,\n",
       " 8: 6515,\n",
       " 0: 3647,\n",
       " 2: 3469,\n",
       " 4: 5059,\n",
       " 5: 3286,\n",
       " 6: 4106,\n",
       " 9: 2714}"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {}\n",
    "for l in titles_labels:\n",
    "    if l not in label_dict:\n",
    "        label_dict[l] = 1\n",
    "    else:\n",
    "        label_dict[l] += 1\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "stem_words_clusters = [{},{},{},{},{},{},{},{},{},{}]\n",
    "print(len(stem_words_clusters))\n",
    "for i in range(len(titles_stem)):\n",
    "    label = titles_labels[i]\n",
    "    stem_use = ' '.join(intersection(titles_stem[i].split(),vecvocab))\n",
    "    for the_stem in stem_use.split():\n",
    "        if the_stem not in stem_words_clusters[label]:\n",
    "            stem_words_clusters[label][the_stem] = 1\n",
    "        else:\n",
    "            stem_words_clusters[label][the_stem] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    sorted_keys = sorted(stem_words_clusters[i].items(), key=lambda kv: kv[1], reverse=True)[:50]\n",
    "    df['cluster '+str(i)] = sorted_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster 0</th>\n",
       "      <th>cluster 1</th>\n",
       "      <th>cluster 2</th>\n",
       "      <th>cluster 3</th>\n",
       "      <th>cluster 4</th>\n",
       "      <th>cluster 5</th>\n",
       "      <th>cluster 6</th>\n",
       "      <th>cluster 7</th>\n",
       "      <th>cluster 8</th>\n",
       "      <th>cluster 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(releas, 3636)</td>\n",
       "      <td>(set, 4533)</td>\n",
       "      <td>(weapon, 3094)</td>\n",
       "      <td>(troop, 4455)</td>\n",
       "      <td>(crash, 3025)</td>\n",
       "      <td>(iranian, 3184)</td>\n",
       "      <td>(milit, 4092)</td>\n",
       "      <td>(missil, 3082)</td>\n",
       "      <td>(arm, 2995)</td>\n",
       "      <td>(egyptian, 2678)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(prison, 394)</td>\n",
       "      <td>(terror, 4453)</td>\n",
       "      <td>(chemic, 1464)</td>\n",
       "      <td>(clash, 2104)</td>\n",
       "      <td>(plane, 2792)</td>\n",
       "      <td>(ship, 96)</td>\n",
       "      <td>(armi, 159)</td>\n",
       "      <td>(test, 1846)</td>\n",
       "      <td>(korean, 2681)</td>\n",
       "      <td>(sentenc, 152)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(video, 261)</td>\n",
       "      <td>(support, 4434)</td>\n",
       "      <td>(arm, 113)</td>\n",
       "      <td>(send, 391)</td>\n",
       "      <td>(jet, 314)</td>\n",
       "      <td>(sanction, 82)</td>\n",
       "      <td>(soldier, 154)</td>\n",
       "      <td>(launch, 417)</td>\n",
       "      <td>(north, 1909)</td>\n",
       "      <td>(armi, 112)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(jail, 167)</td>\n",
       "      <td>(like, 4298)</td>\n",
       "      <td>(evid, 106)</td>\n",
       "      <td>(deploy, 293)</td>\n",
       "      <td>(flight, 296)</td>\n",
       "      <td>(sentenc, 75)</td>\n",
       "      <td>(town, 134)</td>\n",
       "      <td>(system, 344)</td>\n",
       "      <td>(south, 931)</td>\n",
       "      <td>(support, 81)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(document, 136)</td>\n",
       "      <td>(three, 4275)</td>\n",
       "      <td>(destroy, 106)</td>\n",
       "      <td>(soldier, 272)</td>\n",
       "      <td>(miss, 278)</td>\n",
       "      <td>(embassi, 73)</td>\n",
       "      <td>(islamist, 134)</td>\n",
       "      <td>(ballist, 309)</td>\n",
       "      <td>(men, 175)</td>\n",
       "      <td>(journalist, 73)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(hostag, 123)</td>\n",
       "      <td>(would, 4272)</td>\n",
       "      <td>(regim, 85)</td>\n",
       "      <td>(near, 228)</td>\n",
       "      <td>(airlin, 276)</td>\n",
       "      <td>(scientist, 72)</td>\n",
       "      <td>(air, 132)</td>\n",
       "      <td>(defens, 293)</td>\n",
       "      <td>(ship, 173)</td>\n",
       "      <td>(milit, 72)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(demand, 118)</td>\n",
       "      <td>(thousand, 4185)</td>\n",
       "      <td>(develop, 81)</td>\n",
       "      <td>(withdraw, 200)</td>\n",
       "      <td>(land, 262)</td>\n",
       "      <td>(diplomat, 70)</td>\n",
       "      <td>(seiz, 125)</td>\n",
       "      <td>(deploy, 193)</td>\n",
       "      <td>(sale, 132)</td>\n",
       "      <td>(jail, 67)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(journalist, 102)</td>\n",
       "      <td>(case, 4127)</td>\n",
       "      <td>(hand, 77)</td>\n",
       "      <td>(armi, 190)</td>\n",
       "      <td>(passeng, 253)</td>\n",
       "      <td>(woman, 66)</td>\n",
       "      <td>(drone, 118)</td>\n",
       "      <td>(success, 143)</td>\n",
       "      <td>(soldier, 117)</td>\n",
       "      <td>(prison, 65)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(detain, 99)</td>\n",
       "      <td>(top, 4107)</td>\n",
       "      <td>(destruct, 74)</td>\n",
       "      <td>(isra, 165)</td>\n",
       "      <td>(pilot, 236)</td>\n",
       "      <td>(spi, 65)</td>\n",
       "      <td>(target, 115)</td>\n",
       "      <td>(fail, 124)</td>\n",
       "      <td>(export, 117)</td>\n",
       "      <td>(offic, 63)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(order, 95)</td>\n",
       "      <td>(chang, 4095)</td>\n",
       "      <td>(seiz, 74)</td>\n",
       "      <td>(town, 163)</td>\n",
       "      <td>(helicopt, 224)</td>\n",
       "      <td>(media, 63)</td>\n",
       "      <td>(near, 105)</td>\n",
       "      <td>(rocket, 118)</td>\n",
       "      <td>(execut, 107)</td>\n",
       "      <td>(activist, 58)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           cluster 0         cluster 1       cluster 2        cluster 3  \\\n",
       "0     (releas, 3636)       (set, 4533)  (weapon, 3094)    (troop, 4455)   \n",
       "1      (prison, 394)    (terror, 4453)  (chemic, 1464)    (clash, 2104)   \n",
       "2       (video, 261)   (support, 4434)      (arm, 113)      (send, 391)   \n",
       "3        (jail, 167)      (like, 4298)     (evid, 106)    (deploy, 293)   \n",
       "4    (document, 136)     (three, 4275)  (destroy, 106)   (soldier, 272)   \n",
       "5      (hostag, 123)     (would, 4272)     (regim, 85)      (near, 228)   \n",
       "6      (demand, 118)  (thousand, 4185)   (develop, 81)  (withdraw, 200)   \n",
       "7  (journalist, 102)      (case, 4127)      (hand, 77)      (armi, 190)   \n",
       "8       (detain, 99)       (top, 4107)  (destruct, 74)      (isra, 165)   \n",
       "9        (order, 95)     (chang, 4095)      (seiz, 74)      (town, 163)   \n",
       "\n",
       "         cluster 4        cluster 5        cluster 6       cluster 7  \\\n",
       "0    (crash, 3025)  (iranian, 3184)    (milit, 4092)  (missil, 3082)   \n",
       "1    (plane, 2792)       (ship, 96)      (armi, 159)    (test, 1846)   \n",
       "2       (jet, 314)   (sanction, 82)   (soldier, 154)   (launch, 417)   \n",
       "3    (flight, 296)    (sentenc, 75)      (town, 134)   (system, 344)   \n",
       "4      (miss, 278)    (embassi, 73)  (islamist, 134)  (ballist, 309)   \n",
       "5    (airlin, 276)  (scientist, 72)       (air, 132)   (defens, 293)   \n",
       "6      (land, 262)   (diplomat, 70)      (seiz, 125)   (deploy, 193)   \n",
       "7   (passeng, 253)      (woman, 66)     (drone, 118)  (success, 143)   \n",
       "8     (pilot, 236)        (spi, 65)    (target, 115)     (fail, 124)   \n",
       "9  (helicopt, 224)      (media, 63)      (near, 105)   (rocket, 118)   \n",
       "\n",
       "        cluster 8         cluster 9  \n",
       "0     (arm, 2995)  (egyptian, 2678)  \n",
       "1  (korean, 2681)    (sentenc, 152)  \n",
       "2   (north, 1909)       (armi, 112)  \n",
       "3    (south, 931)     (support, 81)  \n",
       "4      (men, 175)  (journalist, 73)  \n",
       "5     (ship, 173)       (milit, 72)  \n",
       "6     (sale, 132)        (jail, 67)  \n",
       "7  (soldier, 117)      (prison, 65)  \n",
       "8   (export, 117)       (offic, 63)  \n",
       "9   (execut, 107)    (activist, 58)  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
